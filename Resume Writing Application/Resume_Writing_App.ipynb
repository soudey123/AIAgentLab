{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Install dependencies\n",
        "\n",
        "!pip install -q streamlit crewai crewai_tools reportlab python-docx pyngrok PyPDF2"
      ],
      "metadata": {
        "id": "Q0i7SvV07fXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FPiQmEK6j1K",
        "outputId": "b40e4530-dc57-4e78-f7b7-2b2bbe2670c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import SerperDevTool, ScrapeWebsiteTool, FileReadTool, MDXSearchTool\n",
        "import io\n",
        "import docx\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "import traceback\n",
        "import tempfile\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "def create_docx(content, filename):\n",
        "    \"\"\"Create a Word document from text content\"\"\"\n",
        "    doc = docx.Document()\n",
        "    for line in content.split('\\n'):\n",
        "        doc.add_paragraph(line)\n",
        "\n",
        "    doc_io = io.BytesIO()\n",
        "    doc.save(doc_io)\n",
        "    doc_io.seek(0)\n",
        "    return doc_io\n",
        "\n",
        "\n",
        "def setup_crew(job_posting_url, github_url, personal_writeup, openai_api_key, serper_api_key, gpt_model, resume_file_path):\n",
        "    \"\"\"Set up CrewAI agents and tasks\"\"\"\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(\"OpenAI API Key is missing. Please provide a valid API key.\")\n",
        "    if not serper_api_key:\n",
        "        raise ValueError(\"Serper API Key is missing. Please provide a valid API key.\")\n",
        "\n",
        "    try:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "        os.environ[\"SERPER_API_KEY\"] = serper_api_key\n",
        "\n",
        "        search_tool = SerperDevTool()\n",
        "        scrape_tool = ScrapeWebsiteTool()\n",
        "\n",
        "        try:\n",
        "            file_read_tool = FileReadTool(file_path=resume_file_path)\n",
        "            semantic_search_tool = MDXSearchTool(file_path=resume_file_path)\n",
        "        except Exception as tool_error:\n",
        "            st.warning(f\"Could not initialize file-related tools: {tool_error}\")\n",
        "            file_read_tool = None\n",
        "            semantic_search_tool = None\n",
        "\n",
        "        researcher = Agent(\n",
        "            role=\"Tech Job Researcher\",\n",
        "            goal=\"Make sure to do amazing analysis on job posting to help job applicants\",\n",
        "            tools=[scrape_tool, search_tool],\n",
        "            verbose=True,\n",
        "            backstory=\"As a Job Researcher, your prowess in navigating and extracting critical information from job postings is unmatched.\",\n",
        "            llm_config={\n",
        "                \"temperature\": 0.7,\n",
        "                \"model_name\": gpt_model,\n",
        "                \"api_key\": openai_api_key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        profiler = Agent(\n",
        "            role=\"Personal Profiler for Engineers\",\n",
        "            goal=\"Do incredible research on job applicants to help them stand out in the job market\",\n",
        "            tools=[scrape_tool, search_tool, file_read_tool, semantic_search_tool],\n",
        "            verbose=True,\n",
        "            backstory=\"Equipped with analytical prowess, you dissect and synthesize information from diverse sources to craft comprehensive personal and professional profiles.\",\n",
        "            llm_config={\n",
        "                \"temperature\": 0.7,\n",
        "                \"model_name\": gpt_model,\n",
        "                \"api_key\": openai_api_key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        resume_strategist = Agent(\n",
        "            role=\"Resume Strategist for Engineers\",\n",
        "            goal=\"Find all the best ways to make a resume stand out in the job market\",\n",
        "            tools=[scrape_tool, search_tool, file_read_tool, semantic_search_tool],\n",
        "            verbose=True,\n",
        "            backstory=\"With a strategic mind and an eye for detail, you excel at refining resumes to highlight the most relevant skills and experiences.\",\n",
        "            llm_config={\n",
        "                \"temperature\": 0.7,\n",
        "                \"model_name\": gpt_model,\n",
        "                \"api_key\": openai_api_key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        interview_preparer = Agent(\n",
        "            role=\"Engineering Interview Preparer\",\n",
        "            goal=\"Create interview questions and talking points based on the resume and job requirements\",\n",
        "            tools=[scrape_tool, search_tool, file_read_tool, semantic_search_tool],\n",
        "            verbose=True,\n",
        "            backstory=\"Your role is crucial in anticipating the dynamics of interviews, formulating key questions and talking points.\",\n",
        "            llm_config={\n",
        "                \"temperature\": 0.7,\n",
        "                \"model_name\": gpt_model,\n",
        "                \"api_key\": openai_api_key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        research_task = Task(\n",
        "            description=f\"Analyze the job posting URL {job_posting_url} to extract key skills, experiences, and qualifications required.\",\n",
        "            expected_output=\"A structured list of job requirements, including necessary skills, qualifications, and experiences.\",\n",
        "            agent=researcher\n",
        "        )\n",
        "\n",
        "        profile_task = Task(\n",
        "            description=f\"Compile a detailed personal and professional profile using GitHub URL {github_url} and personal write-up.\",\n",
        "            expected_output=\"A comprehensive profile document that includes skills, project experiences, contributions, interests, and communication style.\",\n",
        "            agent=profiler\n",
        "        )\n",
        "\n",
        "        resume_strategy_task = Task(\n",
        "            description=\"Using the profile and job requirements, tailor the resume to highlight the most relevant areas.\",\n",
        "            expected_output=\"An updated resume that effectively highlights the candidate's qualifications and experiences.\",\n",
        "            agent=resume_strategist,\n",
        "            output_file=\"tailored_resume.md\",\n",
        "            context=[research_task, profile_task]\n",
        "        )\n",
        "\n",
        "        interview_preparation_task = Task(\n",
        "            description=\"Create potential interview questions and talking points based on the tailored resume and job requirements.\",\n",
        "            expected_output=\"A document containing key questions and talking points for the initial interview.\",\n",
        "            agent=interview_preparer,\n",
        "            output_file=\"interview_materials.md\",\n",
        "            context=[research_task, profile_task, resume_strategy_task]\n",
        "        )\n",
        "\n",
        "        job_application_crew = Crew(\n",
        "            agents=[researcher, profiler, resume_strategist, interview_preparer],\n",
        "            tasks=[research_task, profile_task, resume_strategy_task, interview_preparation_task],\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        job_application_inputs = {\n",
        "            'job_posting_url': job_posting_url,\n",
        "            'github_url': github_url,\n",
        "            'personal_writeup': personal_writeup\n",
        "        }\n",
        "\n",
        "        result = job_application_crew.kickoff(inputs=job_application_inputs)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error setting up CrewAI: {str(e)}\")\n",
        "        st.error(f\"Detailed Traceback:\\n{traceback.format_exc()}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"Resume Tailoring AI Assistant ðŸ“„âœ¨\")\n",
        "\n",
        "    st.sidebar.header(\"API Configuration\")\n",
        "    openai_api_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\",\n",
        "                                           help=\"Your OpenAI API key from platform.openai.com\")\n",
        "    serper_api_key = st.sidebar.text_input(\"Serper API Key\", type=\"password\",\n",
        "                                           help=\"Your Serper API key from serper.dev\")\n",
        "\n",
        "    gpt_models = [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4o\"]\n",
        "    gpt_model = st.sidebar.selectbox(\"Select GPT Model\", options=gpt_models)\n",
        "\n",
        "    st.sidebar.header(\"Job Application Details\")\n",
        "    job_posting_url = st.sidebar.text_input(\"Job Posting URL\")\n",
        "    github_url = st.sidebar.text_input(\"GitHub Profile URL\")\n",
        "    personal_writeup = st.sidebar.text_area(\"Personal Professional Summary\")\n",
        "    resume_file = st.sidebar.file_uploader(\"Upload Resume (Markdown/Text)\", type=['md', 'txt', 'pdf', 'docx'])\n",
        "\n",
        "    if st.sidebar.button(\"Generate Tailored Materials\"):\n",
        "        if not all([openai_api_key, serper_api_key, job_posting_url, github_url, personal_writeup, resume_file]):\n",
        "            st.error(\"Please fill out all required fields.\")\n",
        "            return\n",
        "\n",
        "        with st.spinner('Processing uploaded resume...'):\n",
        "            temp_file_path = None\n",
        "            try:\n",
        "                if resume_file.type == \"application/pdf\":\n",
        "                    pdf_reader = PyPDF2.PdfReader(resume_file)\n",
        "                    resume_content = \"\\n\".join(page.extract_text() or '' for page in pdf_reader.pages)\n",
        "                elif resume_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "                    doc = Document(resume_file)\n",
        "                    resume_content = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
        "                elif resume_file.type in [\"text/plain\", \"text/markdown\"]:\n",
        "                    resume_content = resume_file.getvalue().decode('utf-8', errors='replace')\n",
        "                else:\n",
        "                    st.error(\"Unsupported file type.\")\n",
        "                    return\n",
        "\n",
        "                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.md') as temp_file:\n",
        "                    temp_file.write(resume_content)\n",
        "                    temp_file_path = temp_file.name\n",
        "\n",
        "                final_result = setup_crew(\n",
        "                    job_posting_url, github_url, personal_writeup,\n",
        "                    openai_api_key, serper_api_key, gpt_model, temp_file_path\n",
        "                )\n",
        "\n",
        "                with open(\"./tailored_resume.md\", \"r\", encoding=\"utf-8\") as file:\n",
        "                    markdown_resume_content = file.read()\n",
        "                docx_resume = create_docx(markdown_resume_content, 'tailored_resume.docx')\n",
        "\n",
        "                with open(\"./interview_materials.md\", \"r\", encoding=\"utf-8\") as file:\n",
        "                    markdown_interview_content = file.read()\n",
        "                docx_interview = create_docx(markdown_interview_content, 'interview_materials.docx')\n",
        "\n",
        "                st.session_state[\"docx_resume\"] = docx_resume\n",
        "                st.session_state[\"docx_interview\"] = docx_interview\n",
        "\n",
        "                st.success(\"Materials generated successfully!\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error occurred: {e}\")\n",
        "            finally:\n",
        "                if temp_file_path:\n",
        "                    os.unlink(temp_file_path)\n",
        "    # Display download buttons if content exists\n",
        "    if \"docx_resume\" in st.session_state and \"docx_interview\" in st.session_state:\n",
        "        st.subheader(\"Download Your Tailored Materials\")\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.download_button(\n",
        "                label=\"Download Word Resume\",\n",
        "                data=st.session_state[\"docx_resume\"],\n",
        "                file_name=\"tailored_resume.docx\",\n",
        "                mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n",
        "                key=\"resume_download\"\n",
        "            )\n",
        "        with col2:\n",
        "            st.download_button(\n",
        "                label=\"Download Word Interview Materials\",\n",
        "                data=st.session_state[\"docx_interview\"],\n",
        "                file_name=\"interview_materials.docx\",\n",
        "                mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n",
        "                key=\"interview_materials_download\"\n",
        "            )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any previous Streamlit instances\n",
        "!kill -9 $(lsof -t -i:8501)\n",
        "\n",
        "# Start a new ngrok tunnel\n",
        "#public_url = ngrok.connect(port='8501')\n",
        "#print(f\"Public URL for the app: {public_url}\")\n",
        "\n",
        "# Configure ngrok with your authtoken\n",
        "ngrok.set_auth_token(\"<YOUR TOKEN\")  # Replace with your actual token\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8501, proto=\"http\")  # Specify proto=\"http\"\n",
        "print(f\"Public URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjkftj-F-k31",
        "outputId": "113bd03d-ba06-443c-a53f-58f5c3351216"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://ba8d-34-139-79-236.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "PoQxQJ8V-qV8"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}